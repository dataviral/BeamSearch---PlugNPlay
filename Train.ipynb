{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_data, Dataset, index2Sent, collate_fn_train, collate_fn_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/news_summary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 10000\n",
    "MAX_TEXT_LEN = 500\n",
    "MAX_SUM_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the data: 4514\n",
      "Length of the data after dropping nan: 4396\n"
     ]
    }
   ],
   "source": [
    "data, w2i, i2w = get_data(DATA_PATH, NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(data, w2i, MAX_TEXT_LEN, MAX_SUM_LEN, isTrain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Seq2Seq import Seq2Seq\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = NUM_WORDS + 4\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 128\n",
    "BATCH_SIZE = 12\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, BATCH_SIZE, num_workers=8, shuffle=True, collate_fn=collate_fn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10 Loss: 9.210471153259277\n",
      "Step: 20 Loss: 9.089808464050293\n",
      "Step: 30 Loss: 9.113744735717773\n",
      "Step: 40 Loss: 9.088224411010742\n",
      "Step: 50 Loss: 9.086456298828125\n",
      "Step: 60 Loss: 9.070070266723633\n",
      "Step: 70 Loss: 9.06949520111084\n",
      "Step: 80 Loss: 9.092009544372559\n",
      "Step: 90 Loss: 9.075565338134766\n",
      "Step: 100 Loss: 9.085577011108398\n",
      "Step: 110 Loss: 9.0734224319458\n",
      "Step: 120 Loss: 9.111626625061035\n",
      "Step: 130 Loss: 9.076574325561523\n",
      "Step: 140 Loss: 9.066244125366211\n",
      "Step: 150 Loss: 9.04426383972168\n",
      "Step: 160 Loss: 9.093443870544434\n",
      "Step: 170 Loss: 9.059752464294434\n",
      "Step: 180 Loss: 9.063953399658203\n",
      "Step: 190 Loss: 9.077128410339355\n",
      "Step: 200 Loss: 9.085248947143555\n",
      "Step: 210 Loss: 9.087504386901855\n",
      "Step: 220 Loss: 9.125009536743164\n",
      "Step: 230 Loss: 9.101083755493164\n",
      "Step: 240 Loss: 9.06827163696289\n",
      "Step: 250 Loss: 9.071728706359863\n",
      "Step: 260 Loss: 9.079447746276855\n",
      "Step: 270 Loss: 9.087320327758789\n",
      "Step: 280 Loss: 9.104023933410645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-39f11ae92d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# 4. SUM the losses then divide by number of tokens and finally call backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FNC/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FNC/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    total_loss = 0.\n",
    "    for batch_num, ((x, xlens), (y, ylens)) in enumerate(dataloader):\n",
    "\n",
    "        # setup tensors\n",
    "        x = x.long().to(DEVICE)\n",
    "        y = y.long().to(DEVICE)\n",
    "        \n",
    "#         print(x.size(), y.size())\n",
    "        \n",
    "        # clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # generate predictions\n",
    "        # output: (BATCH_SIZE, time_steps, NUM_WORDS)\n",
    "        output = model(x, xlens, y)\n",
    "\n",
    "        ### Calculate Loss\n",
    "        # 1. y must be shifted by 1 for loss calc. since outputs should not not contain <sos>\n",
    "        y_true = torch.cat([y[:, 1:], torch.ones((y.size(0), 1)).long().to(DEVICE) * w2i[\"<pad>\"]], dim=-1)\n",
    "\n",
    "        # 2. Ouput shape for loss calculation must be of the form (BATCH_SIZE, NUM_WORDS, *)\n",
    "        # Refer pytorch docs for more details\n",
    "        loss = criterion(output.permute(0, 2, 1), y_true)\n",
    "\n",
    "        # 3. Mask the loss. Needed since we have padding which is not needed\n",
    "        # Can avoid if using pack_padded sequence?\n",
    "        num_tokens = 0\n",
    "        for i, yl in enumerate(ylens):\n",
    "            loss[i, yl-1:] *= 0 # yl-1 to remove <sos>\n",
    "            num_tokens += yl - 1\n",
    "\n",
    "        # 4. SUM the losses then divide by number of tokens and finally call backward\n",
    "        loss = loss.sum() / num_tokens\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "        # Adjust parameters\n",
    "        optimizer.step()\n",
    "        if (batch_num + 1) % 10 == 0:\n",
    "             print(\"Step: {} Loss: {}\".format(batch_num + 1, loss.item()))\n",
    "        total_loss += loss.item()\n",
    "    print(\"EP: {} Loss: {}\".format(i + 1, total_loss / len(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[i][:xlens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[i][:ylens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2Sent(x[i, :xlens[i]].cpu().numpy(), i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2Sent(y[i, :ylens[i]].cpu().numpy(), i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2Sent(output.argmax(dim=-1)[i].cpu().numpy(), i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.argmax(dim=-1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2w[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
